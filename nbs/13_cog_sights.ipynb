{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e7e42f-88de-40a4-9411-63206a7a1836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/ltxhyhhn7jn3xwtvypy7f9ym0000gn/T/ipykernel_41987/2415962420.py:199: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, TypedDict, Union\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from pydantic import BaseModel\n",
    "from pystac_client import Client\n",
    "from rasterio.mask import mask\n",
    "from rasterio.session import AWSSession\n",
    "from shapely.geometry import shape\n",
    "from stackstac import stack\n",
    "\n",
    "NL_classification_values = {\n",
    "    2: \"natural forests\",\n",
    "    3: \"natural short vegetation\",\n",
    "    4: \"natural water\",\n",
    "    5: \"mangroves\",\n",
    "    6: \"bare\",\n",
    "    7: \"snow\",\n",
    "    8: \"wet natural forests\",\n",
    "    9: \"natural peat forests\",\n",
    "    10: \"wet natural short vegetation\",\n",
    "    11: \"natural peat short vegetation\",\n",
    "    12: \"crop\",\n",
    "    13: \"built\",\n",
    "    14: \"non-natural tree cover\",\n",
    "    15: \"non-natural short vegetation\",\n",
    "    16: \"non-natural water\",\n",
    "    17: \"wet non-natural tree cover\",\n",
    "    18: \"non-natural peat tree cover\",\n",
    "    19: \"wet non-natural short vegetation\",\n",
    "    20: \"non-natural peat short vegetation\",\n",
    "    21: \"non-natural bare\"\n",
    "}\n",
    "\n",
    "DEFAULT_COG_PATH = \"s3://gfw-data-lake/umd_glad_dist_alerts/v20250329/raster/epsg-4326/cog/default.tif\"\n",
    "INTENSITY_COG_PATH = \"s3://gfw-data-lake/umd_glad_dist_alerts/v20250329/raster/epsg-4326/cog/intensity.tif\"\n",
    "STAC_API_URL = \"https://eoapi.zeno-staging.ds.io/stac\"\n",
    "AWS_PROFILE = \"zeno_internal_sso\"\n",
    "REFERENCE_DATE = datetime(2015, 1, 1)\n",
    "\n",
    "def convert_date_range_to_days(date_range):\n",
    "    start_date = datetime.strptime(str(date_range[0])[:10], \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(str(date_range[1])[:10], \"%Y-%m-%d\")\n",
    "    return (start_date - REFERENCE_DATE).days, (end_date - REFERENCE_DATE).days, start_date, end_date\n",
    "\n",
    "def load_alert_data(geometry):\n",
    "    session = boto3.Session(profile_name=AWS_PROFILE)\n",
    "    with rasterio.Env(AWSSession(session), AWS_REQUEST_PAYER=\"requester\"):\n",
    "        with rasterio.open(DEFAULT_COG_PATH) as src1:\n",
    "            default_data, _ = mask(src1, geometry, crop=True)\n",
    "        with rasterio.open(INTENSITY_COG_PATH) as src2:\n",
    "            intensity_data, _ = mask(src2, geometry, crop=True)\n",
    "    return default_data[0], intensity_data[0]\n",
    "\n",
    "def load_natural_lands_mosaic(aoi_geom, start_date, end_date):\n",
    "    stac = Client.open(STAC_API_URL)\n",
    "    search = stac.search(\n",
    "        collections=[\"natural-lands-map-v1-1\"],\n",
    "        intersects=aoi_geom,\n",
    "        datetime=f\"{start_date.date().isoformat()}/{end_date.date().isoformat()}\",\n",
    "        max_items=50,\n",
    "    )\n",
    "    items = list(search.get_items())\n",
    "    if not items:\n",
    "        raise ValueError(\"No Natural Lands items found for AOI.\")\n",
    "\n",
    "    print(f\"Found {len(items)} items\")\n",
    "\n",
    "    da = stack(\n",
    "        items,\n",
    "        bounds_latlon=aoi_geom.bounds,\n",
    "        snap_bounds=True,\n",
    "        epsg=4326\n",
    "    )\n",
    "\n",
    "    # Apply chunking\n",
    "    da = da.chunk({\"x\": 1024, \"y\": 1024})\n",
    "\n",
    "\n",
    "    # Collapse time dimension if multiple timestamps\n",
    "    if \"time\" in da.dims:\n",
    "        da = da.astype(\"int16\").max(\"time\")\n",
    "\n",
    "    return da.squeeze()\n",
    "\n",
    "\n",
    "#@tool\n",
    "def filter_and_count_pixels(state: Dict) -> Dict:\n",
    "    \"\"\"Filters pixels from COGs using confidence, intensity, and date thresholds, then counts land cover class occurrences.\"\"\"\n",
    "    parsed = state[\"parsed_params\"]\n",
    "\n",
    "    print(\"Parsed parameters:\", parsed)\n",
    "\n",
    "    start_days, end_days, start_date, end_date = convert_date_range_to_days(\n",
    "        (parsed[\"start_date\"], parsed[\"end_date\"])\n",
    "    )\n",
    "    geometry = [shape(parsed[\"aoi\"][\"geometry\"])]\n",
    "\n",
    "    # Load and process data\n",
    "    encoded, intensities = load_alert_data(geometry)\n",
    "    confidence = encoded // 10000\n",
    "    days_since_2015 = encoded % 10000\n",
    "\n",
    "    land_cover = load_natural_lands_mosaic(shape(parsed[\"aoi\"][\"geometry\"]), start_date, end_date)\n",
    "    land_cover = land_cover.squeeze()\n",
    "\n",
    "    if land_cover.shape != confidence.shape:\n",
    "        raise ValueError(f\"Shape mismatch: {land_cover.shape} vs {confidence.shape}\")\n",
    "\n",
    "    max_days = (datetime.today() - REFERENCE_DATE).days\n",
    "    days_since_2015[days_since_2015 == 9999] = days_since_2015[days_since_2015 < 9999].max()\n",
    "\n",
    "    valid_mask = (\n",
    "        (confidence >= parsed[\"confidence_threshold\"]) &\n",
    "        (days_since_2015 >= start_days) &\n",
    "        (days_since_2015 <= end_days) &\n",
    "        (days_since_2015 < max_days) &\n",
    "        (intensities >= parsed[\"intensity_threshold\"])\n",
    "    )\n",
    "\n",
    "    results = {}\n",
    "    valid_lc = land_cover.values[valid_mask]\n",
    "    unique_classes, counts = np.unique(valid_lc, return_counts=True)\n",
    "    for cls, count in zip(unique_classes, counts):\n",
    "        results[int(cls)] = {\n",
    "            \"class\": NL_classification_values.get(int(cls), \"Unknown\"),\n",
    "            \"count\": int(count)\n",
    "        }\n",
    "\n",
    "    result = {\n",
    "        \"summary_json\": {\n",
    "            \"start_date\": parsed[\"start_date\"],\n",
    "            \"end_date\": parsed[\"end_date\"],\n",
    "            \"current_max_days_possible_based_on_today\": max_days,\n",
    "            \"current_min_days_since_2015_in_aoi\": days_since_2015.min(),\n",
    "            \"current_max_days_since_2015_in_aoi\": days_since_2015.max(),\n",
    "            \"confidence_threshold\": parsed[\"confidence_threshold\"],\n",
    "            \"intensity_threshold\": parsed[\"intensity_threshold\"],\n",
    "            \"results\": results\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class ParsedParams(BaseModel):\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    confidence_threshold: float\n",
    "    intensity_threshold: int\n",
    "    aoi: Union[str, Dict]  # named region or GeoJSON\n",
    "\n",
    "\n",
    "class GraphState(TypedDict, total=False):\n",
    "    input: str\n",
    "    parsed_params: Dict\n",
    "    results: Dict\n",
    "    summary: str\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "class ParseParamsNode:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"input_text\"],\n",
    "            template=\"\"\"\n",
    "Extract the following parameters from the input text:\n",
    "- start_date (YYYY-MM-DD)\n",
    "- end_date (YYYY-MM-DD)\n",
    "- confidence_threshold (float)\n",
    "- intensity_threshold (int)\n",
    "- aoi (string or GeoJSON)\n",
    "\n",
    "Input:\n",
    "{input_text}\n",
    "\n",
    "Return a JSON object only with these keys and values.\n",
    "Please output ONLY valid JSON with all braces closed. Do not add any extra text or explanations.\n",
    "Make sure the JSON is valid and complete.\n",
    "\"\"\"\n",
    "        )\n",
    "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
    "\n",
    "    def run(self, input_text: str) -> ParsedParams:\n",
    "        response = self.chain.run(input_text=input_text)\n",
    "\n",
    "        # Parse JSON output\n",
    "        try:\n",
    "            params_dict = json.loads(response)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to parse JSON from LLM output: {response}\") from e\n",
    "\n",
    "        # Return Pydantic model\n",
    "        return ParsedParams(**params_dict)\n",
    "\n",
    "\n",
    "parser_node = ParseParamsNode()\n",
    "\n",
    "def parse_message(state: GraphState) -> GraphState:\n",
    "    parsed = parser_node.run(state[\"input\"])\n",
    "    return {**state, \"parsed_params\": parsed}\n",
    "\n",
    "def filter_and_count_node(state: GraphState) -> GraphState:\n",
    "    result = filter_and_count_pixels({\"parsed_params\": state[\"parsed_params\"].dict()})\n",
    "    return {**state, \"results\": result[\"summary_json\"][\"results\"]}\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant summarizing geospatial alert statistics.\"),\n",
    "    (\"human\", \"Here are the results:\\n{summary_json}\")\n",
    "])\n",
    "summarize_chain = summary_prompt | llm | RunnableLambda(lambda msg: {\"summary\": msg.content})\n",
    "\n",
    "def summarize_results(state: GraphState) -> GraphState:\n",
    "    summary_text = summarize_chain.invoke({\"summary_json\": state[\"results\"]})[\"summary\"]\n",
    "    return {**state, \"summary\": summary_text}\n",
    "\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"parse_message\", parse_message)\n",
    "builder.add_node(\"filter_and_count\", filter_and_count_node)\n",
    "builder.add_node(\"summarize_results\", summarize_results)\n",
    "\n",
    "builder.set_entry_point(\"parse_message\")\n",
    "builder.add_edge(\"parse_message\", \"filter_and_count\")\n",
    "builder.add_edge(\"filter_and_count\", \"summarize_results\")\n",
    "builder.add_edge(\"summarize_results\", END)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1265cf3f-afbd-41b9-9ac6-8f72e22b9492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/ltxhyhhn7jn3xwtvypy7f9ym0000gn/T/ipykernel_41987/2415962420.py:202: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = self.chain.run(input_text=input_text)\n",
      "/var/folders/3l/ltxhyhhn7jn3xwtvypy7f9ym0000gn/T/ipykernel_41987/2415962420.py:221: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  result = filter_and_count_pixels({\"parsed_params\": state[\"parsed_params\"].dict()})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed parameters: {'start_date': '2019-01-01', 'end_date': '2020-12-31', 'confidence_threshold': 3.0, 'intensity_threshold': 50, 'aoi': {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-75.0, -3.0], [-70.0, -3.0], [-70.0, -6.0], [-75.0, -6.0], [-75.0, -3.0]]]}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilliannethomas/Desktop/work/wri/project-zeno/.venv/lib/python3.11/site-packages/pystac_client/item_search.py:888: FutureWarning: get_items() is deprecated, use items() instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "{'summary_json': {'start_date': '2019-01-01', 'end_date': '2020-12-31', 'current_max_days_possible_based_on_today': 3799, 'current_min_days_since_2015_in_aoi': 880, 'current_max_days_since_2015_in_aoi': 1543, 'confidence_threshold': 3.0, 'intensity_threshold': 50, 'results': {2: {'class': 'natural forests', 'count': 659}, 4: {'class': 'natural water', 'count': 555}, 6: {'class': 'bare', 'count': 336}, 8: {'class': 'wet natural forests', 'count': 271}, 9: {'class': 'natural peat forests', 'count': 213}, 10: {'class': 'wet natural short vegetation', 'count': 115}, 11: {'class': 'natural peat short vegetation', 'count': 188}, 12: {'class': 'crop', 'count': 3096}, 13: {'class': 'built', 'count': 20}, 15: {'class': 'non-natural short vegetation', 'count': 9}}}}\n"
     ]
    }
   ],
   "source": [
    "geojson_str = \"\"\"\n",
    "{\n",
    "  \"type\": \"Feature\",\n",
    "  \"geometry\": {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "      [\n",
    "        [-75.0, -3.0],\n",
    "        [-70.0, -3.0],\n",
    "        [-70.0, -6.0],\n",
    "        [-75.0, -6.0],\n",
    "        [-75.0, -3.0]\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "initial_state = {\n",
    "    \"input\": (\n",
    "        \"Find alerts from January 1, 2019 to December 31, 2020, with confidence of 3 and intensity above 50 \"\n",
    "        \"in this AOI (in GeoJSON format): ```json\\n\" +\n",
    "        geojson_str.strip() +\n",
    "        \"\\n```\"\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "final_state = graph.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb51847e-f3c6-464f-9d8f-b2b2a50418a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Find alerts from January 1, 2019 to December 31, 2020, with confidence of 3 and intensity above 50 in this AOI (in GeoJSON format): ```json\\n{\\n  \"type\": \"Feature\",\\n  \"geometry\": {\\n    \"type\": \"Polygon\",\\n    \"coordinates\": [\\n      [\\n        [-75.0, -3.0],\\n        [-70.0, -3.0],\\n        [-70.0, -6.0],\\n        [-75.0, -6.0],\\n        [-75.0, -3.0]\\n      ]\\n    ]\\n  }\\n}\\n```',\n",
       " 'parsed_params': ParsedParams(start_date='2019-01-01', end_date='2020-12-31', confidence_threshold=3.0, intensity_threshold=50, aoi={'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-75.0, -3.0], [-70.0, -3.0], [-70.0, -6.0], [-75.0, -6.0], [-75.0, -3.0]]]}}),\n",
       " 'results': {2: {'class': 'natural forests', 'count': 659},\n",
       "  4: {'class': 'natural water', 'count': 555},\n",
       "  6: {'class': 'bare', 'count': 336},\n",
       "  8: {'class': 'wet natural forests', 'count': 271},\n",
       "  9: {'class': 'natural peat forests', 'count': 213},\n",
       "  10: {'class': 'wet natural short vegetation', 'count': 115},\n",
       "  11: {'class': 'natural peat short vegetation', 'count': 188},\n",
       "  12: {'class': 'crop', 'count': 3096},\n",
       "  13: {'class': 'built', 'count': 20},\n",
       "  15: {'class': 'non-natural short vegetation', 'count': 9}},\n",
       " 'summary': 'Here is a summary of the geospatial alert statistics:\\n\\n- Natural forests: 659 alerts\\n- Natural water: 555 alerts\\n- Bare land: 336 alerts\\n- Wet natural forests: 271 alerts\\n- Natural peat forests: 213 alerts\\n- Wet natural short vegetation: 115 alerts\\n- Natural peat short vegetation: 188 alerts\\n- Crop fields: 3096 alerts\\n- Built-up areas: 20 alerts\\n- Non-natural short vegetation: 9 alerts'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9bca12-a4c1-4563-a620-3384a3dcbcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Summary: Here is a summary of the geospatial alert statistics:\n",
      "\n",
      "- Natural forests: 659 alerts\n",
      "- Natural water: 555 alerts\n",
      "- Bare land: 336 alerts\n",
      "- Wet natural forests: 271 alerts\n",
      "- Natural peat forests: 213 alerts\n",
      "- Wet natural short vegetation: 115 alerts\n",
      "- Natural peat short vegetation: 188 alerts\n",
      "- Crop fields: 3096 alerts\n",
      "- Built-up areas: 20 alerts\n",
      "- Non-natural short vegetation: 9 alerts\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Summary:\", final_state[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce306182-7050-4b0e-827a-a071846577b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
