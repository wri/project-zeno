{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Date: 8 Nov, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from src.tools.location.location_matcher import LocationMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GADM_CSV_PATH = \"../data/gadm.csv\"\n",
    "location_matcher = LocationMatcher(GADM_CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Location Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationInput(BaseModel):\n",
    "    \"\"\"Input schema for location finder tool\"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        description=\"Name of the location to search for. Can be a city, region, or country name.\"\n",
    "    )\n",
    "    threshold: int = Field(\n",
    "        default=70,\n",
    "        description=\"Minimum similarity score (0-100) to consider a match. Default is 70.\",\n",
    "        ge=0,\n",
    "        le=100,\n",
    "    )\n",
    "\n",
    "\n",
    "@tool(\"location-tool\", args_schema=LocationInput, return_direct=True)\n",
    "def location_tool(query: str, threshold: int = 70) -> dict:\n",
    "    \"\"\"Find locations and their administrative hierarchies given a place name.\n",
    "      Returns matches at different administrative levels (ADM2, ADM1, ISO) with their IDs and names.\n",
    "\n",
    "    Args:\n",
    "        query (str): Location name to search for\n",
    "        threshold (int, optional): Minimum similarity score. Defaults to 70.\n",
    "\n",
    "    Returns:\n",
    "        dict: matching locations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matches = location_matcher.find_matches(query, threshold=threshold)\n",
    "        return matches\n",
    "    except Exception as e:\n",
    "        return f\"Error finding locations: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tool.invoke(input={\"query\": \"lisbon portugal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "llm = ChatOllama(model=\"mistral:instruct\", temperature=0)\n",
    "tools = [location_tool]\n",
    "tool_node = ToolNode(tools)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"find datasets near Milan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_result = tool_node.invoke(\n",
    "    {\"messages\": [AIMessage(content=\"\", tool_calls=result.tool_calls)]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_result[\"messages\"][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
