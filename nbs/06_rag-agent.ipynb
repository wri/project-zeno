{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "local_llm = \"qwen2.5:7b\"\n",
    "# llm = ChatOllama(model=local_llm, temperature=0)\n",
    "# llm = ChatOllama(model=\"qwen2.5:7b\", temperature=0)\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "db = Chroma(\n",
    "        persist_directory=\"../data/chroma_layers\", \n",
    "        embedding_function=embedder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = \"\"\"You are a World Resources Institute (WRI) assistant specializing in dataset recommendations.\n",
    "\n",
    "Instructions:\n",
    "1. Use the following context to inform your response:\n",
    "{context}\n",
    "\n",
    "2. User Question:\n",
    "{question}\n",
    "\n",
    "3. Response Format to be a valid JSON with list of datasets in the following format:\n",
    "    {{\n",
    "        \"datasets\": [\n",
    "            {{\n",
    "                \"dataset\": The slug of the dataset,\n",
    "                \"explanation\": A two-line explanation of why this dataset is relevant to the user's problem\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I am interested in biodiversity conservation in Argentina\"\n",
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context(docs):\n",
    "    fmt_docs = []\n",
    "    for doc in docs:\n",
    "        dataset = doc.metadata['dataset']\n",
    "        content = (\n",
    "            f\"Dataset: {dataset}\\n{doc.page_content}\"\n",
    "        )\n",
    "        fmt_docs.append(content)\n",
    "    \n",
    "    # Join all formatted documents with double newlines\n",
    "    return \"\\n\\n\".join(fmt_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_txt = make_context(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt_fmt = rag_prompt.format(context=docs_txt, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_prompt_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = llm.invoke([HumanMessage(content=rag_prompt_fmt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(generation.content)[\"datasets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "from IPython.display import Image, display, Markdown\n",
    "from langgraph.graph import START, MessagesState, StateGraph, END, add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    question: str  # User question\n",
    "    generation: str  # LLM generation\n",
    "    loop_step: Annotated[int, operator.add]\n",
    "    documents: List[str]  # List of retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "def generate(state):\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    loop_step = state.get(\"loop_step\", 0)\n",
    "\n",
    "    # RAG generation\n",
    "    docs_txt = make_context(documents)\n",
    "    rag_prompt_fmt = rag_prompt.format(context=docs_txt, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_fmt)])\n",
    "    datasets = json.loads(generation.content)[\"datasets\"]\n",
    "    for dataset in datasets:\n",
    "        dataset[\"uri\"] = f\"https://data-api.globalforestwatch.org/dataset/{dataset['dataset']}\"\n",
    "        dataset[\"tilelayer\"] = f\"https://tiles.globalforestwatch.org/{dataset['dataset']}/latest/dynamic/{{z}}/{{x}}/{{y}}.png\"\n",
    "\n",
    "    return {\"generation\": datasets, \"loop_step\": loop_step + 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = StateGraph(GraphState)\n",
    "\n",
    "wf.add_node(\"retrieve\", retrieve)\n",
    "wf.add_node(\"generate\", generate)\n",
    "\n",
    "wf.add_edge(START, \"retrieve\")\n",
    "wf.add_edge(\"retrieve\", \"generate\")\n",
    "wf.add_edge(\"generate\", END)\n",
    "\n",
    "graph = wf.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph(xray=False).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"I am interested in tree cover loss over amazon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = json.loads(result[\"generation\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
